{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pJbYXou6chZf",
    "outputId": "73f61863-e03e-4aad-c420-ecf62a937f5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Apr 11 07:03:43 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   34C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "I6TYYk_nvk3D"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "import string\n",
    "import nltk\n",
    "from string import punctuation\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from gensim.parsing.preprocessing import remove_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MZykjbQEwQeV",
    "outputId": "27d7e815-f8ad-43d9-df04-87704e789f3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "Cey9-Aq4wQhz"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/content/sample_data/training_set_rel3.tsv', sep = '\\t', encoding = 'ISO-8859-1')\n",
    "\n",
    "df_test = pd.read_csv('/content/sample_data/test_set.tsv', sep = '\\t', encoding = 'ISO-8859-1' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "id": "DcE07RIxwQkx",
    "outputId": "d078d041-4feb-4255-dbe8-38ba0d9f3de9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>rater1_trait1</th>\n",
       "      <th>rater1_trait2</th>\n",
       "      <th>rater1_trait3</th>\n",
       "      <th>rater1_trait4</th>\n",
       "      <th>rater1_trait5</th>\n",
       "      <th>rater1_trait6</th>\n",
       "      <th>rater2_trait1</th>\n",
       "      <th>rater2_trait2</th>\n",
       "      <th>rater2_trait3</th>\n",
       "      <th>rater2_trait4</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set  ... rater3_trait5  rater3_trait6\n",
       "0         1          1  ...           NaN            NaN\n",
       "1         2          1  ...           NaN            NaN\n",
       "2         3          1  ...           NaN            NaN\n",
       "3         4          1  ...           NaN            NaN\n",
       "4         5          1  ...           NaN            NaN\n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "id": "980-3NTCwQnP",
    "outputId": "b1ecf3e3-94f9-463b-c614-65503d80b6b3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_predictionid</th>\n",
       "      <th>domain2_predictionid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2383</td>\n",
       "      <td>1</td>\n",
       "      <td>I believe that computers have a positive effec...</td>\n",
       "      <td>2383</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2384</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1, I know some problems have came up...</td>\n",
       "      <td>2384</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2385</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear to whom it @MONTH1 concern, Computers are...</td>\n",
       "      <td>2385</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2386</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, @CAPS3 has come to my atte...</td>\n",
       "      <td>2386</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2387</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local newspaper, I think that people have...</td>\n",
       "      <td>2387</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set  ... domain1_predictionid  domain2_predictionid\n",
       "0      2383          1  ...                 2383                   NaN\n",
       "1      2384          1  ...                 2384                   NaN\n",
       "2      2385          1  ...                 2385                   NaN\n",
       "3      2386          1  ...                 2386                   NaN\n",
       "4      2387          1  ...                 2387                   NaN\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "id": "W4Vge5MxwQqa",
    "outputId": "c188f7f7-8b15-4efe-b18f-06c6438ea0af"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Dear local newspaper, I think effects computers have on people are great learning skills/affects because they give us time to chat with friends/new people, helps us learn about the globe(astronomy) and keeps us out of troble! Thing about! Dont you think so? How would you feel if your teenager is always on the phone with friends! Do you ever time to chat with your friends or buisness partner about things. Well now - there's a new way to chat the computer, theirs plenty of sites on the internet to do so: @ORGANIZATION1, @ORGANIZATION2, @CAPS1, facebook, myspace ect. Just think now while your setting up meeting with your boss on the computer, your teenager is having fun on the phone not rushing to get off cause you want to use it. How did you learn about other countrys/states outside of yours? Well I have by computer/internet, it's a new way to learn about what going on in our time! You might think your child spends a lot of time on the computer, but ask them so question about the economy, sea floor spreading or even about the @DATE1's you'll be surprise at how much he/she knows. Believe it or not the computer is much interesting then in class all day reading out of books. If your child is home on your computer or at a local library, it's better than being out with friends being fresh, or being perpressured to doing something they know isnt right. You might not know where your child is, @CAPS2 forbidde in a hospital bed because of a drive-by. Rather than your child on the computer learning, chatting or just playing games, safe and sound in your home or community place. Now I hope you have reached a point to understand and agree with me, because computers can have great effects on you or child because it gives us time to chat with friends/new people, helps us learn about the globe and believe or not keeps us out of troble. Thank you for listening.\""
      ]
     },
     "execution_count": 110,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['essay'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KhG82cz8wQuO",
    "outputId": "d5e6e28c-3d26-45e0-f19b-d888b1720e6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12976 entries, 0 to 12975\n",
      "Data columns (total 28 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   essay_id        12976 non-null  int64  \n",
      " 1   essay_set       12976 non-null  int64  \n",
      " 2   essay           12976 non-null  object \n",
      " 3   rater1_domain1  12976 non-null  int64  \n",
      " 4   rater2_domain1  12976 non-null  int64  \n",
      " 5   rater3_domain1  128 non-null    float64\n",
      " 6   domain1_score   12976 non-null  int64  \n",
      " 7   rater1_domain2  1800 non-null   float64\n",
      " 8   rater2_domain2  1800 non-null   float64\n",
      " 9   domain2_score   1800 non-null   float64\n",
      " 10  rater1_trait1   2292 non-null   float64\n",
      " 11  rater1_trait2   2292 non-null   float64\n",
      " 12  rater1_trait3   2292 non-null   float64\n",
      " 13  rater1_trait4   2292 non-null   float64\n",
      " 14  rater1_trait5   723 non-null    float64\n",
      " 15  rater1_trait6   723 non-null    float64\n",
      " 16  rater2_trait1   2292 non-null   float64\n",
      " 17  rater2_trait2   2292 non-null   float64\n",
      " 18  rater2_trait3   2292 non-null   float64\n",
      " 19  rater2_trait4   2292 non-null   float64\n",
      " 20  rater2_trait5   723 non-null    float64\n",
      " 21  rater2_trait6   723 non-null    float64\n",
      " 22  rater3_trait1   128 non-null    float64\n",
      " 23  rater3_trait2   128 non-null    float64\n",
      " 24  rater3_trait3   128 non-null    float64\n",
      " 25  rater3_trait4   128 non-null    float64\n",
      " 26  rater3_trait5   128 non-null    float64\n",
      " 27  rater3_trait6   128 non-null    float64\n",
      "dtypes: float64(22), int64(5), object(1)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b8zds0TLwQ3K",
    "outputId": "ed2d294c-50e9-4216-a15d-5d0eddb6b028"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4254 entries, 0 to 4253\n",
      "Data columns (total 5 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   essay_id              4254 non-null   int64  \n",
      " 1   essay_set             4254 non-null   int64  \n",
      " 2   essay                 4254 non-null   object \n",
      " 3   domain1_predictionid  4254 non-null   int64  \n",
      " 4   domain2_predictionid  600 non-null    float64\n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 166.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "EImLhfvFwQ7p",
    "outputId": "f404e577-ed3d-40c5-c5e6-7b98d3c95ad0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_set                                              essay  domain1_score\n",
       "0          1  Dear local newspaper, I think effects computer...              8\n",
       "1          1  Dear @CAPS1 @CAPS2, I believe that using compu...              9\n",
       "2          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...              7\n",
       "3          1  Dear Local Newspaper, @CAPS1 I have found that...             10\n",
       "4          1  Dear @LOCATION1, I know having computers has a...              8"
      ]
     },
     "execution_count": 113,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dropna(axis = 1,inplace=True)\n",
    "df_train = df_train.drop(columns=['rater1_domain1', 'rater2_domain1', 'essay_id'])\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ImLt0aAPwRDb",
    "outputId": "81b21b0f-6933-44b3-ea16-c7cdefb35a8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 7, 8])"
      ]
     },
     "execution_count": 114,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['essay_set'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "id": "igrj_Jo1wRGm",
    "outputId": "53432bfb-3ce5-484b-9d3c-d52c1eeb3084"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Dear @LOCATION1, I know having computers has a positive effect on people. The computers connect families, contain information which is great for peoples education, and are very conveint. Computors are a step into the future and we should take advantage of it. First off the internet or e-mail will help family members connect. My family, which lives @NUM1 hours away by car, love to talk with me by e-mail. This helps me connect with my family and is just another reason why we should have computors. Another reason that includes family is when the family is just sitting around and are calling everywhere just to find a board game, it would just be easier to go online to find it. This way it would be quick and easy to find that one board game. The last reason why a computer would help a family is if a family wants to get in to any kinds of activities and they need the number they could just go online. On the internet the family could find the numbers, the and some information about it. This way more and more families can do activities together. As one can see the computer is bringing more and more families together. An other reason why the computers are good for society is educations. With information at the tip of your fingers more and more people will want to learn. Now a days people try to find the out, but will all the tools on the computers mae people get the education. Secondly computers are another way to go to collage. If you arn't up to going to school/collage because your sick. You wouldn't have to miss anything because with a click of a button you will have the materials needed for what was missed. Lastly everyone knows that in @LOCATION2 most classrooms can't afford one computer. The children want computors so hard. If they were to get one it would change so much. They would be able to learn so much more than before. The children could lean about different countries far away. As a result computers would improve the way we learn. The last reason why computers are so helpful is convience. Now a say the world is crazy, so if we don't have to go out or talk to someone we won't. The computer will offer the ability to confrence will other people so that there would be communication between work parttners. With the ability to talk with another for work would make us a lighter nation. This is only one of the many reasons computers are very conviente, subssiquently computers are conviente because you could book flights, vacations, rentals, and much more. With a click of a button you should be going to @CAPS1 or a nice vacation.\""
      ]
     },
     "execution_count": 115,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['essay'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "XzducdvDwmaj"
   },
   "outputs": [],
   "source": [
    "def essay_to_wordlist(essay_v, remove_stopwords):\n",
    "    #essay_v = re.sub(\"[^a-zA-Z]\", \" \", essay_v)\n",
    "    essay_v = re.sub('\\[.*?\\]', '', essay_v)\n",
    "    essay_v = re.sub('https?://\\S+|www\\.\\S+', '', essay_v)\n",
    "    essay_v = re.sub('<.*?>+', '', essay_v)\n",
    "    essay_v = re.sub('[%s]' % re.escape(string.punctuation), '', essay_v)\n",
    "    essay_v = re.sub('\\n', '', essay_v)\n",
    "    essay_v = re.sub('\\w*\\d\\w*', '', essay_v)\n",
    "    words = essay_v.lower().split()\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    return (words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "OaWBfI2qwmdj"
   },
   "outputs": [],
   "source": [
    "def essay_to_sentences(essay_v, remove_stopwords):\n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    raw_sentences = tokenizer.tokenize(essay_v.strip())\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentence) > 0:\n",
    "            sentences.append(essay_to_wordlist(raw_sentence, remove_stopwords))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "7JsW3ZBpwmg0"
   },
   "outputs": [],
   "source": [
    "#Make Feature Vector from the words list of an Essay.\n",
    "def makeFeatureVec(words, model, num_features):\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    num_words = 0.\n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            num_words += 1\n",
    "            featureVec = np.add(featureVec,model[word])        \n",
    "    featureVec = np.divide(featureVec,num_words)\n",
    "    return featureVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "4kYkIm9owmjf"
   },
   "outputs": [],
   "source": [
    "#Main function to generate the word vectors for word2vec model.\n",
    "def getAvgFeatureVecs(essays, model, num_features):\n",
    "    counter = 0\n",
    "    essayFeatureVecs = np.zeros((len(essays),num_features),dtype=\"float32\")\n",
    "    for essay in essays:\n",
    "        essayFeatureVecs[counter] = makeFeatureVec(essay, model, num_features)\n",
    "        counter = counter + 1\n",
    "    return essayFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fYpUJxtlwmmH",
    "outputId": "c7d52875-054f-4a93-cfb4-273e8de9e2fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 120,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "YDEll06Fwmo_"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Lambda, Flatten\n",
    "from keras.models import Sequential, load_model, model_from_config\n",
    "import keras.backend as K\n",
    "\n",
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(300, dropout=0.4, recurrent_dropout=0.4, input_shape=[1, 300], return_sequences=True))\n",
    "    model.add(LSTM(64, recurrent_dropout=0.4))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "mfDqK0RS0Icd"
   },
   "outputs": [],
   "source": [
    "X = df_train.drop(columns=['domain1_score'], axis=1)\n",
    "y = df_train['domain1_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xz-hIWmXwms3",
    "outputId": "1ed78f7b-2e72-4706-d2eb-e0d339792e7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------Fold 1--------\n",
      "\n",
      "Training Word2Vec Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_24 (LSTM)               (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_25 (LSTM)               (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "163/163 [==============================] - 5s 11ms/step - loss: 79.7805 - mae: 4.9351\n",
      "Epoch 2/10\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 40.9870 - mae: 3.5606\n",
      "Epoch 3/10\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 36.9219 - mae: 3.5968\n",
      "Epoch 4/10\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 33.8773 - mae: 3.5545\n",
      "Epoch 5/10\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 30.9904 - mae: 3.3585\n",
      "Epoch 6/10\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 29.1624 - mae: 3.1830\n",
      "Epoch 7/10\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 26.7723 - mae: 2.9654\n",
      "Epoch 8/10\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 22.3197 - mae: 2.7301\n",
      "Epoch 9/10\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 18.4254 - mae: 2.4376\n",
      "Epoch 10/10\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 17.1627 - mae: 2.2906\n",
      "[[ 6.]\n",
      " [ 7.]\n",
      " [ 9.]\n",
      " ...\n",
      " [30.]\n",
      " [33.]\n",
      " [29.]] [ 8  7 10 ... 47 33 40]\n",
      "Kappa Score: 0.9222639899920366\n",
      "\n",
      "--------Fold 2--------\n",
      "\n",
      "Training Word2Vec Model...\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_26 (LSTM)               (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_27 (LSTM)               (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "163/163 [==============================] - 5s 11ms/step - loss: 86.9152 - mae: 5.1393\n",
      "Epoch 2/10\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 45.9413 - mae: 3.7365\n",
      "Epoch 3/10\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 34.2622 - mae: 3.4826\n",
      "Epoch 4/10\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 32.0625 - mae: 3.4785\n",
      "Epoch 5/10\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 29.3974 - mae: 3.2309\n",
      "Epoch 6/10\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 27.2974 - mae: 3.0829\n",
      "Epoch 7/10\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 21.8639 - mae: 2.7410\n",
      "Epoch 8/10\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 20.9399 - mae: 2.6387\n",
      "Epoch 9/10\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 18.2275 - mae: 2.4284\n",
      "Epoch 10/10\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 15.9255 - mae: 2.2643\n",
      "[[ 9.]\n",
      " [ 9.]\n",
      " [10.]\n",
      " ...\n",
      " [31.]\n",
      " [26.]\n",
      " [33.]] [ 8  8  9 ... 35 35 40]\n",
      "Kappa Score: 0.9213743630487358\n",
      "\n",
      "--------Fold 3--------\n",
      "\n",
      "Training Word2Vec Model...\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_28 (LSTM)               (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_29 (LSTM)               (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "163/163 [==============================] - 6s 12ms/step - loss: 90.1189 - mae: 5.2022\n",
      "Epoch 2/10\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 45.7570 - mae: 3.7697\n",
      "Epoch 3/10\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 35.7781 - mae: 3.4972\n",
      "Epoch 4/10\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 32.3835 - mae: 3.4616\n",
      "Epoch 5/10\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 31.8878 - mae: 3.4150\n",
      "Epoch 6/10\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 27.8622 - mae: 3.1308\n",
      "Epoch 7/10\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 26.4949 - mae: 3.0115\n",
      "Epoch 8/10\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 22.0525 - mae: 2.7165\n",
      "Epoch 9/10\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 20.0813 - mae: 2.5574\n",
      "Epoch 10/10\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 16.5036 - mae: 2.3276\n",
      "[[ 6.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " ...\n",
      " [31.]\n",
      " [32.]\n",
      " [34.]] [10  7 12 ... 40 32 40]\n",
      "Kappa Score: 0.921004079859482\n",
      "\n",
      "--------Fold 4--------\n",
      "\n",
      "Training Word2Vec Model...\n",
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_30 (LSTM)               (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_31 (LSTM)               (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "163/163 [==============================] - 6s 12ms/step - loss: 86.8722 - mae: 5.1307\n",
      "Epoch 2/10\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 43.3932 - mae: 3.7459\n",
      "Epoch 3/10\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 34.3123 - mae: 3.5479\n",
      "Epoch 4/10\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 31.2661 - mae: 3.4799\n",
      "Epoch 5/10\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 29.4447 - mae: 3.3330\n",
      "Epoch 6/10\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 28.3144 - mae: 3.1748\n",
      "Epoch 7/10\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 24.6986 - mae: 2.9172\n",
      "Epoch 8/10\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 20.9400 - mae: 2.7011\n",
      "Epoch 9/10\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 17.8115 - mae: 2.4575\n",
      "Epoch 10/10\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 15.2940 - mae: 2.3256\n",
      "[[16.]\n",
      " [13.]\n",
      " [ 9.]\n",
      " ...\n",
      " [28.]\n",
      " [24.]\n",
      " [31.]] [ 9  8  6 ... 44 30 40]\n",
      "Kappa Score: 0.9167853506665805\n",
      "\n",
      "--------Fold 5--------\n",
      "\n",
      "Training Word2Vec Model...\n",
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_32 (LSTM)               (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_33 (LSTM)               (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "163/163 [==============================] - 6s 12ms/step - loss: 90.9177 - mae: 5.2313\n",
      "Epoch 2/10\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 44.3341 - mae: 3.7080\n",
      "Epoch 3/10\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 35.7542 - mae: 3.5379\n",
      "Epoch 4/10\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 30.8337 - mae: 3.3969\n",
      "Epoch 5/10\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 30.3647 - mae: 3.2910\n",
      "Epoch 6/10\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 27.4059 - mae: 3.0693\n",
      "Epoch 7/10\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 23.6313 - mae: 2.8196\n",
      "Epoch 8/10\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 21.5575 - mae: 2.6266\n",
      "Epoch 9/10\n",
      "163/163 [==============================] - 2s 13ms/step - loss: 18.7475 - mae: 2.4878\n",
      "Epoch 10/10\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 17.3796 - mae: 2.3747\n",
      "[[ 9.]\n",
      " [ 9.]\n",
      " [ 9.]\n",
      " ...\n",
      " [34.]\n",
      " [13.]\n",
      " [30.]] [ 9 10  8 ... 35 36 33]\n",
      "Kappa Score: 0.9211798383222198\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from gensim.models import Word2Vec\n",
    "from matplotlib import pyplot\n",
    "\n",
    "cv = KFold(n_splits = 5, shuffle = True)\n",
    "results = []\n",
    "y_pred_list = []\n",
    "\n",
    "count = 1\n",
    "for traincv, testcv in cv.split(df_train):\n",
    "    print(\"\\n--------Fold {}--------\\n\".format(count))\n",
    "    X_test, X_train, y_test, y_train = df_train.iloc[testcv], df_train.iloc[traincv], y.iloc[testcv], y.iloc[traincv]\n",
    "    \n",
    "    train_essays = X_train['essay']\n",
    "    test_essays = X_test['essay']\n",
    "    \n",
    "    sentences = []\n",
    "    \n",
    "    for essay in train_essays:\n",
    "      sentences += essay_to_sentences(essay, remove_stopwords = True)\n",
    "            \n",
    "    # Initializing variables for word2vec model.\n",
    "    num_features = 300 \n",
    "    min_word_count = 40\n",
    "    num_workers = 4\n",
    "    context = 10\n",
    "    downsampling = 1e-3\n",
    "\n",
    "    print(\"Training Word2Vec Model...\")\n",
    "    model = Word2Vec(sentences, workers=num_workers, size=num_features, min_count = min_word_count, window = context, sample = downsampling)\n",
    "\n",
    "    model.init_sims(replace=True)\n",
    "    model.wv.save_word2vec_format('word2vecmodel.bin', binary=True)\n",
    "\n",
    "    clean_train_essays = []\n",
    "    \n",
    "    # Generate training and testing data word vectors.\n",
    "    for essay_v in train_essays:\n",
    "        clean_train_essays.append(essay_to_wordlist(essay_v, remove_stopwords=True))\n",
    "    trainDataVecs = getAvgFeatureVecs(clean_train_essays, model, num_features)\n",
    "    \n",
    "    clean_test_essays = []\n",
    "    for essay_v in test_essays:\n",
    "        clean_test_essays.append(essay_to_wordlist( essay_v, remove_stopwords=True ))\n",
    "    testDataVecs = getAvgFeatureVecs( clean_test_essays, model, num_features )\n",
    "    \n",
    "    trainDataVecs = np.array(trainDataVecs)\n",
    "    testDataVecs = np.array(testDataVecs)\n",
    "    # Reshaping train and test vectors to 3 dimensions. (1 represnts one timestep)\n",
    "    trainDataVecs = np.reshape(trainDataVecs, (trainDataVecs.shape[0], 1, trainDataVecs.shape[1]))\n",
    "    testDataVecs = np.reshape(testDataVecs, (testDataVecs.shape[0], 1, testDataVecs.shape[1]))\n",
    "    \n",
    "    lstm_model = get_model()\n",
    "    #lstm_model.compile(loss='mse', optimizer='adam')\n",
    "    lstm_model.fit(trainDataVecs, y_train, batch_size=64, epochs=10)\n",
    "    #lstm_model.load_weights('./model_weights/final_lstm.h5')\n",
    "    y_pred = lstm_model.predict(testDataVecs)\n",
    "    \n",
    "    #if count == 5:\n",
    "    #     lstm_model.save('final_lstm_1.h5')\n",
    "    \n",
    "    # Round y_pred to the nearest integer.\n",
    "    y_pred = np.around(y_pred)\n",
    "    #print(y_pred, y_test.values)\n",
    "    # Evaluate the model on the evaluation metric. \"Quadratic mean averaged Kappa\"\n",
    "    result = cohen_kappa_score(y_test.values,y_pred,weights='quadratic')\n",
    "    print(\"Kappa Score: {}\".format(result))\n",
    "    results.append(result)\n",
    "\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6-MQPdoEw3UI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fh-EK9BKw3XA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ulCMHgo2w3aT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5zPkuhDswRKr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6sCxm2wpwRN5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "P100.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
